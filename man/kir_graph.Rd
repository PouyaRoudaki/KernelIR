% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/kir_graph.R
\name{kir_graph}
\alias{kir_graph}
\title{kNN-based estimator (vectorised, fast) with tie/duplicate-aware neighbors}
\usage{
kir_graph(X, Y, Knn = 5L, eps = 1e-12, ky = NULL, bandwidth_scale = 1)
}
\arguments{
\item{X}{Numeric matrix (or object coercible to one) of predictors with
\eqn{n} rows (samples) and \eqn{d_X} columns (features).}

\item{Y}{Numeric matrix (or object coercible to one) of responses with
\eqn{n} rows (samples) and \eqn{d_Y} columns.}

\item{Knn}{Positive integer. Number of nearest neighbors used to estimate
the conditional variance structure. Internally clipped to
\eqn{\min(K, n-1)}.}

\item{eps}{Small positive numeric scalar \eqn{\varepsilon > 0} used to
stabilise the ratio \eqn{\widehat E_i / \widehat V_i} when
\eqn{\widehat V_i \approx 0}. Defaults to \code{1e-12}.}

\item{ky}{Kernel on \eqn{Y}: either a \pkg{kernlab} kernel object or a
function of the form \code{function(A, B = NULL)} returning the Gram
matrix. If \code{NULL} (default), an RBF kernel with median-heuristic
bandwidth scaled by \code{bandwidth_scale} is used.}

\item{bandwidth_scale}{Positive numeric scalar applied to the
median-heuristic bandwidth when \code{ky = NULL}. Defaults to \code{1}.}
}
\value{
A single numeric scalar: the estimated dependence measure
  \eqn{\widehat D \in (-\infty, 1]}, where values close to 1 indicate
  strong dependence between \eqn{X} and \eqn{Y} and values close to 0
  indicate near independence.
}
\description{
A computationally efficient version of \code{kir_graph} that replaces the
inner loop over \eqn{j \neq i} with vectorised matrix operations. It
computes the same estimator
\deqn{\widehat D = 1 - \frac{1}{n}\sum_{i=1}^n
      \frac{\widehat E_i}{\max(\widehat V_i,\, \varepsilon)}}
as defined in Proposition 7, but is typically 10â€“100\eqn{\times} faster
than \code{kir_graph} for moderate-to-large \eqn{n} (e.g.\ \eqn{n = 1500}).
}
\details{
The neighbor matrix \eqn{N_{\cdot}} is computed once via \code{get_knn(X, Knn+1)}.
Inside the outer loop over \eqn{i}, point \eqn{i} is masked out of every
neighbor set \eqn{N_j} (\eqn{j \neq i}) by replacing its index with
\code{NA} and retaining the first \code{Knn} valid entries.  Because
\code{get_knn} returns \eqn{K+1} neighbors, at most one entry per row is
removed, so backfilling (random sampling from the remaining pool) is needed
only in the rare case that \eqn{i} appeared in \eqn{N_j}.

Once the clean \eqn{(n-1) \times K} index matrix is available, the
double sum
\deqn{\sum_{j \neq i}\sum_{\ell \in N_j}(v_j - v_\ell)^2,
      \quad v = K_Y[\,,i]}
is evaluated in two vectorised steps: a gather \code{v[Nmat_clean]}
followed by \code{sum((v_j - v_neigh)^2)}, avoiding any inner R loop
over \eqn{j}.
}
\examples{
set.seed(1)
n <- 200
X <- matrix(rnorm(n * 2), n, 2)

# Strong dependence: Y is a noisy function of X
Y_dep <- X[, 1, drop = FALSE] + 0.3 * rnorm(n)
kir_graph(X, Y_dep, Knn = 5)   # close to 1

# Near independence
Y_ind <- matrix(rnorm(n), n, 1)
kir_graph(X, Y_ind, Knn = 5)   # close to 0

# Custom kernel
if (requireNamespace("kernlab", quietly = TRUE)) {
  k <- kernlab::rbfdot(sigma = 0.5)
  kir_graph(X, Y_dep, Knn = 5, ky = k)
}
}
\seealso{
\code{\link{get_knn}} for the tie/duplicate-aware neighbor search.
}
